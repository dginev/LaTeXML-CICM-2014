\documentclass{llncs}
\usepackage[citestyle=alphabetic,style=alphabetic,urldate=long]{biblatex}
\bibliography{kbib/kwarc}
\usepackage{xspace}
\usepackage{latexml}
%\usepackage[show]{ed}
\def\ebook{\mbox{E-book}\xspace}
\def\ebooks{\mbox{E-books}\xspace}
\def\epub{\textsc{epub}\xspace}
\def\svg{\textsc{svg}\xspace}
\def\zip{\textsc{zip}\xspace}
\def\tikz{\texttt{TikZ}\xspace}

\title{\ebooks and Graphics with \LaTeXML}
\author{Deyan Ginev\inst{1} \and Bruce~R.~Miller\inst{2} \and Silviu Oprea\inst{3}}
\institute{Computer Science, Jacobs University Bremen, Germany
 \and National Institute of Standards and Technology, Gaithersburg, MD, USA
 \and University of Oxford, Oxford, UK.}
\date{\today}

\begin{document}
\maketitle
\begin{abstract} 
Marked by the highlights of native generation of \epub \ebooks and \tikz support for creating \svg images, we present an annual report of {\LaTeXML} development in 2013. {\LaTeXML} provides a reimplementation of the {\TeX} parser, geared towards preserving macro semantics; it supports an array of output formats, notably \HTML5, \epub, \XHTML\ and its own \LaTeX-near \XML.

Other highlights include enhancing performance when used inside high-throughput build systems, via incorporating a native \zip archive workflow, as well as a simplified installation procedure that now allows to deploy LaTeXML as a cloud service. To this end, we also introduce an official plugin-based scheme for publishing new features that go beyond the core scope of LaTeXML, such as web services or unconventional post-processors.

The software suite has now migrated to GitHub and we welcome forks and patches from the wider FLOSS community.
\end{abstract}

\section{Introduction}
Another busy year of {\LaTeXML} \footnote{see \url{http://dlmf.nist.gov/LaTeXML/}} development has gone by;
while we've not completely accomplished all the tasks we'd hoped for (c.f. \cite{GinMil:latexmlCICM13}),
we've finished others including some we hadn't originally planned.
While it was originally developed for NIST's Digital Library of Mathematical Functions\footnote{see \url{http://dlmf.nist.gov}},
where it continues to serve, we continue to find additional applications.
One, carried out this year, was the natural extension of the system to generate \epub documents. 

A move to GitHub along with
the adoption of coding standards, and a reorganization should enhance
the ability of the community to both contribute to the core software
and extend it through a new plugin architecture being refined.

%\begin{itemize}
%\item finished move to GitHub, fork us and send patches!
%\item Project is alive and stronger than ever (do "gitstats /path/to/git-checkout-of/LaTeXML html; firefox html/index.html"). We have had a steady increase in commits - 200 in 2010, 400 in 2011, 600 in 2012 and 800 in 2013.
%\item We have a brand new CPAN-friendly, plugin-based contribution model for fancy features
%\item added support for \epub (discussion on mobi?)
%\item added support for Tikz (dsicsussion on XYPic and other formats?)
%\item native ZIP conversion workflow, with arXiv's algorithm for determining main TeX files.
%\item ? one-pass conversion to HTML (with Bibliography)
%\item ? Additional commitment to quality control in development (perltidy, perlcritic)
%\item cloud-friendly - now possible to install locally with cpanm on cloud platform such as Heroku (I will try that today!) 
%\end{itemize}

\section{Reorganization}\label{reorganization}
We have reorganized both our code development and our code base.
In the first sense, we have moved our repository to GitHub\footnote{see \url{https://github.com/brucemiller/LaTeXML}} 
where you can more conveniently browse our code, or obtain the latest version.
We have also ported our Trac ticket database to GitHub's Issues,
so you can also report bugs and request features at the same place.

Along with the move to GitHub came more opportunities to share
code and development which called for clearer coding standards.
We have made a commitment to code quality and formatting by
adopting \texttt{perltidy} and \texttt{perlcritic} policies,
which were adapted to the polyglot context of \TeX, Perl, \XML,
\XSLT, and more, and which are automatically enforced by \texttt{git} mechanisms.

In the second sense, we have reorganized the code itself to more clearly
separate the modules related to the separate phases of processing.
At the same time, we enable ``conversion as an API'', offering a connection and code sharing between those phases when more
complex processing is called for, such as carrying a single \TeX\ source
file through the full processing to \HTML, or even \epub (see \ref{ebooks}).
In particular, it provides better support for daemonized processing, foundational to batch conversions and web service deployments.

This reorganization positions us to develop a plugin architecture that allows modular extensions
that cover both new \LaTeX\ styles and bindings, but also
include enhanced postprocessing for more sophisticated applications
such as s\TeX. The authors have already refactored the three flavors of {\LaTeXML} web servers, an alternative grammar for math parsing,
as well as an extension for converting {\TeX} formulas into queries for the MathWebSearch search engine, as 5 separate repositories, also hosted on GitHub.
The true power of the new contribution model is revealed when combined with Perl's CPAN distribution and dependency management system,
 which will allow for single command installation of any LaTeXML-based project and its full dependency tree.

\section{\ebooks}\label{ebooks}
The newest version of \epub, version 3, is primarily a packaging
of \HTML\ pages representing chapters or sections into a structured
\zip archive. The big step forward for the scientific community
is that it now calls for the use of \MathML\
to represent mathematics. Since \LaTeXML\ is already generating \HTML,
with embedded \MathML, and allows that output to be split into
multiple pages as specified by the user, it seemed an obvious
and natural extension to generate \epub documents. Moreover, the
web-service spin-off projects had already called for and drafted the compression of the resulting
directory of generated content into a \zip
archive.  Thus, with appropriate rearrangment of the pieces,
and the addition of a Manifest of the correct structure,
we have all the basic components needed to generate \epub documents. We have generated a number of \epub documents and successfully validated them against the official \texttt{idpf} validator\footnote{see \url{http://validator.idpf.org/}}.

We subsequently considered to also add support for Amazon's proprietary \texttt{mobi} \ebook format. However, at the time of writing the \texttt{mobi} ecosystem is transitioning to the new Amazon Kindle Format 8 (\texttt{AKF8}), which aims to more fully align with \epub 3.0. Finally, the lack of an open ecosystem around the format prevented us from repeating the quick and painless design process for the \epub output, so we did not venture further.

% More on Mobi from my November email:
% I would actually want to bring some points up for discussion. I have been reading into MOBI today and my conclusion so far is that adding support for it would be difficult and would probably go against LaTeXML's principles of enabling open standards.
% My summary of the MOBI resources on the web:
%  - proprietary format owned by Amazon
%  - based on an old open precursor to EPUB (now explicitly shunned by the IDPF)
%  - binary format, with special proprietary extensions related to DRM
%  - a new Amazon Kindle Format 8 will try to largely align with EPUB 3, but remain just as incompatible.
%  - there is *NO* official open MOBI spec out there (and probably there won't be one for the AKF8 either).
%  - from what I can tell, the best converters to MOBI are either owned by Amazon or perform elaborate reverse-engineering of examples to derive the actual spec (Calibre).
% All of that taken into account, I am currently leaning towards not developing a .mobi output capability for LaTeXML, but instead focus on creating high quality EPUB 3 and leave it to specialized eBook converters to do the transition.
% Bruce has shared a fist sentiment of keeping any MOBI capability external to the LaTeXML core, if the format is indeed as closed and impenetrable as I have found it to be.


\section{Graphics}\label{graphics}
Before we turn our attention to graphics,
a brief digression may be in order.
There are two main approaches currently used to generate
\HTML\ from \TeX. The first approach,
exemplified by \texttt{tex4ht}, uses the actual \TeX\ engine
to process the source by redefining certain commands to drop
\verb|\special| data into the normal \texttt{dvi} output file.
Instead of \texttt{dvips}, a special \texttt{dvi} processor then deciphers
that augmented \texttt{dvi}
to infer and construct the appropriate \HTML.
In the second approach, used by \LaTeXML, a program
is developed which emulates \TeX\ for the most part
but interprets some macros
specially, so that they produce \XML\ directly.

The first approach has the advantage of (usually)
allowing the processing of arbitrary \TeX\ and \LaTeX\ packages,
although the resulting \HTML\ may not reflect the intended
structure nor semantics.
The challenges are in the \TeX\ programming necessary to
insert the \verb|\specials|, generating valid \HTML,
and in whether sufficient semantic structure can be
recovered from the \texttt{dvi}.

The second approach has the advantage of having more
direct control of the generated output.
It is easier, though not trivial, to extend to new
\XML\ structures.  Furthermore, \LaTeXML\
uses an intermediate \XML\ format which preserves
the semantic structure. It is fundamentally XML aware, so it produces valid \XML.
A feature of \LaTeXML\ bindings is that macro
control sequences can be defined to be ``Constructors''
which directly construct the \XML\ representation
of their content.
The challenge, of course, is to emulate \TeX\ sufficiently well to
process complex packages, or alternatively, to
develop \LaTeXML-specific bindings for them.

In either approach, \LaTeX\ packages that define
macros with semantic intent, or which imply a specific \XML\
output, must be dealt with
individually or else the semantics will be lost.

Within that context, we were skeptical when Michael Kohlhase
initially posed the proposition: Was \LaTeXML's engine good
enough to implement the \tikz package and generate \svg?
Presumably any semantics implied by \tikz markup isn't so critical,
but the expected \svg obviously is.
The package is so large and complex, not to mention
its development so fast-moving, that creating \LaTeXML-specific
bindings for all its commands is impractical.  However,
it is designed to pass all processed graphics through
a relatively small driver layer, and in fact alre has a \texttt{tex4ht} driver for producing \svg!

The main tasks, then, were to implement \LaTeXML\ bindings
for that driver and improve \LaTeXML's engine to cope
with the sophisticated \TeX\ macro usage in the higher
layers of \texttt{pgf} and \tikz.

Ultimately, we succeeded beyond our expectations.
Although the results are not perfect,
\LaTeXML\ now successfully processes 3/4 of the
first page\footnote{see \url{http://www.texample.net/tikz/examples/all/}} of \tikz examples on the
{\TeX}ample.net website, generating valid
\HTML5, with text and \MathML\ combined.
In contrast, \texttt{tex4ht} succeeds on slightly more
than half the examples, often producing invalid markup,
and doesn't support \MathML\ embedded in the \svg.
It must be admitted, however, that \LaTeXML\ is \emph{very}
slow at processing \tikz markup!

In the process, we have further improved the
fidelity of the \TeX\ emulation, introduced
a (currently very rudimentary) mechanism for estimating
the size of displayed objects and exercised the
integration of both \MathML\ and \svg\ into \HTML. 
Additionally, {\LaTeXML} now has its own {\TeX} profiler, which
offers binding developers per-macro feedback on
exclusive runtimes, helping to identify core conversion bottlenecks.
These improvements are beneficial even outside the graphics milestone and
contribute to an overall better {\LaTeXML} ecosystem.

Areas needing further work are \tikz' matrix
structure which currently clashes with \LaTeXML's handling
of alignments; inaccuracies of \LaTeXML's sizing of objects;
and, of course, examples involving other exotic packages
not yet known to \LaTeXML.  We plan to test against
the entire suite of examples at {\TeX}ample.net to discover
other weaknesses and further improve the module.

Beyond \tikz, we are hoping to leverage this experience and apply
it to supporting the \texttt{xy} package, another
popular and powerful system.  It seems to have a less
well-defined driver layer and we are in the early stages of
discovering the smallest set of macros that could serve that
function. Nevertheless, we have had some preliminary, proof-of-concept, success.
We already have minimal support, for the \texttt{pstricks}
package, but with its Postscript oriented design,
it is more time consuming to develop further bindings.

\section{Outlook}
The initial success with \tikz processing is quite
gratifying, but it needs refinement, and we look forward to testing
on a larger scale. We also intend
to extend our reach to the \texttt{xy} packages.
Other \ebook\ formats such as \texttt{AKF8} should be possible with
specializations of manifest generation and other fine tuning.
Surprisingly, generating Word and OpenOffice formats shares many features
with {\ebook}s; of course finding the documentation and writing the {\XSLT}
transformations from \LaTeXML's native {\XML} to Word's will be challenging.

Our move to GitHub, the code reorganization and the plugin contribution model should make it easier
for users to use and adapt the system, not to mention contributing
back patches and improvements that will help our developement.

\printbibliography

\end{document}